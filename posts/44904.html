<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Pytorch学习 | YoSheep's 学习笔记</title><meta name="author" content="YoSheep"><meta name="copyright" content="YoSheep"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="近期准备开始做毕设，因为要用来实现一些算法的功能，因此在对比了各种框架后还是选择了pytorch。相较于其他的深度学习框架，pytorch的使用更加的简洁，也易于理解，并且，还有一个选择它的原因在于Github上有很多的开源代码都是使用PyTorch进行开发的。而且Pytorch也有着越来越完善的扩展库，可以说正处于当打之年。 Pytorch加载数据​	如何使用pytorch加载读取数据，主要涉及">
<meta property="og:type" content="article">
<meta property="og:title" content="Pytorch学习">
<meta property="og:url" content="https://yosheep.github.io/posts/44904.html">
<meta property="og:site_name" content="YoSheep&#39;s 学习笔记">
<meta property="og:description" content="近期准备开始做毕设，因为要用来实现一些算法的功能，因此在对比了各种框架后还是选择了pytorch。相较于其他的深度学习框架，pytorch的使用更加的简洁，也易于理解，并且，还有一个选择它的原因在于Github上有很多的开源代码都是使用PyTorch进行开发的。而且Pytorch也有着越来越完善的扩展库，可以说正处于当打之年。 Pytorch加载数据​	如何使用pytorch加载读取数据，主要涉及">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yosheep.github.io/img/yeah_circle.jpg">
<meta property="article:published_time" content="2024-04-09T11:20:52.000Z">
<meta property="article:modified_time" content="2024-12-06T01:07:22.762Z">
<meta property="article:author" content="YoSheep">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yosheep.github.io/img/yeah_circle.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yosheep.github.io/posts/44904.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: YoSheep","link":"链接: ","source":"来源: YoSheep's 学习笔记","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Pytorch学习',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-12-06 12:07:22'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.1.1"><link rel="alternate" href="/atom.xml" title="YoSheep's 学习笔记" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/yeah_circle.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/background.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="YoSheep's 学习笔记"><span class="site-name">YoSheep's 学习笔记</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Pytorch学习</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-09T11:20:52.000Z" title="发表于 2024-04-09 21:20:52">2024-04-09</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-12-06T01:07:22.762Z" title="更新于 2024-12-06 12:07:22">2024-12-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.3k</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Pytorch学习"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/posts/44904.html#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/posts/44904.html" itemprop="commentCount"><i class="fa-solid fa-spinner fa-spin"></i></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>近期准备开始做毕设，因为要用来实现一些算法的功能，因此在对比了各种框架后还是选择了pytorch。相较于其他的深度学习框架，pytorch的使用更加的简洁，也易于理解，并且，还有一个选择它的原因在于Github上有很多的开源代码都是使用PyTorch进行开发的。而且Pytorch也有着越来越完善的扩展库，可以说正处于当打之年。</p>
<h2 id="Pytorch加载数据"><a href="#Pytorch加载数据" class="headerlink" title="Pytorch加载数据"></a>Pytorch加载数据</h2><p>​	如何使用pytorch加载读取数据，主要涉及到两个类 <strong>Dataset</strong> 和 <strong>Dataloader</strong> 。</p>
<h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p>​	对数据进行加载时，例如对一堆数据，例如此时图中的”垃圾“，dataset主要是告诉我们如何获取数据，例如提取可回收数据，并对其进行一个编号。同时还会获取数据相应的label，因此<strong>dataset主要是提供一种方式来获取数据及其真实的label</strong>。</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240409193934903.png" alt="image-20240409193934903"></p>
<h4 id="Dataloader"><a href="#Dataloader" class="headerlink" title="Dataloader"></a>Dataloader</h4><p>​	可用来对dataset整理出来的数据进行打包，主要是为了为后面的网络提供不同的数据形式。</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240409220235552.png" alt="image-20240409220235552"></p>
<p>对Dataset来说，如何获取每一个数据及其label、告诉我们总共有多少个数据，是它主要实现的功能。</p>
<p>以下是一个读取数据示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, label_dir</span>):</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.labek_dir = label_dir</span><br><span class="line">        self.path = os.path.join(self.root_dir, self.labek_dir)</span><br><span class="line">        self.img_path = os.listdir(self.path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_name = self.img_path[idx]</span><br><span class="line">        img_item_path = os.path.join(self.root_dir, self.labek_dir, img_name)</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_item_path)</span><br><span class="line">        label = self.labek_dir</span><br><span class="line">        <span class="keyword">return</span> img, label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path)</span><br><span class="line"></span><br><span class="line">root_dir = <span class="string">&quot;..\data\\train&quot;</span></span><br><span class="line">ants_label_dir =<span class="string">&quot;ants_image&quot;</span></span><br><span class="line">bees_label_dir =<span class="string">&quot;bees_image&quot;</span></span><br><span class="line">ants_dataset =Mydata(root_dir, ants_label_dir)</span><br><span class="line">bees_dataset =Mydata(root_dir, bees_label_dir)</span><br><span class="line"></span><br><span class="line"><span class="comment"># img_ant_zero, label_zero = ants_dataset[0]</span></span><br><span class="line"><span class="comment"># img_ant_zero.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 整个数据集，可以直接相加是因为Dataset中已经写好了__add__方法，可以直接通过+来相加__len__方法中返回的值</span></span><br><span class="line">train_dataset = ants_dataset + bees_dataset</span><br></pre></td></tr></table></figure>

<h2 id="TensorBoard的使用"><a href="#TensorBoard的使用" class="headerlink" title="TensorBoard的使用"></a>TensorBoard的使用</h2><p>TensorBoard是一个可视化工具，它可以用来展示网络图、张量的指标变化、张量的分布情况等。特别是在训练网络的时候，我们可以设置不同的参数（比如：权重W、偏置B、卷积层数、全连接层数等），使用TensorBoader可以很直观的帮我们进行参数的选择。它通过运行一个本地服务器，来监听6006端口。在浏览器发出请求时，分析训练时记录的数据，绘制训练过程中的图像。</p>
<p>通过SummaryWriter类，创建一个该类的对象，使用add_scalar方法即可绘制图像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)  <span class="comment"># 将内容存储在logs文件夹下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># writer.add_image()</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=x&quot;</span>, i, i)</span><br><span class="line">	<span class="comment"># y=x(tag) : 数据标识符</span></span><br><span class="line">    <span class="comment"># i(scalar_value) : 值(纵坐标)</span></span><br><span class="line">    <span class="comment"># i(global_step) : 要记录的全局步值(横坐标)</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418112852543.png" alt="image-20240418112852543"></p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418113533396.png" alt="image-20240418113533396"></p>
<p>再尝试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)  <span class="comment"># 将内容存储在logs文件夹下</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># writer.add_image()</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>, <span class="number">2</span>*i, i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418113938434.png" alt="image-20240418113938434"></p>
<p>再每次想要得到一个新的图像时，需要对tag参数进行改变，pytorch会自动进行拟合。例如我在tag为y&#x3D;2x的图像上绘制一个y&#x3D;3x的数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>, <span class="number">3</span>*i, i)</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418114536801.png" alt="image-20240418114536801"></p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>以下是一个用于区分蚂蚁和蜜蜂进行二分类的例子，其中有训练数据集和验证数据集，对于训练数据集其中一种组织形式是会指定告诉我们每个数据集的label：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240414185432176.png"></p>
<p>此时我们要通过add_image方法对一组图像进行研究，对于这个方法的参数，有如下必须的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Args:</span><br><span class="line">	tag (str): Data identifier</span><br><span class="line">	img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data</span><br><span class="line">	global_step (int): Global step value to record</span><br></pre></td></tr></table></figure>

<p>纵坐标相比add_scalar多了很多类型，此时我们如果使用Image库的open方法读取图片的话，返回的类型是不满足要求的，我们需要读取numpy类型的图像数据。</p>
<p>转换方式：<code>img_array = np.array(img)</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)  <span class="comment"># 将内容存储在logs文件夹下</span></span><br><span class="line">image_path = <span class="string">&quot;../data/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">img_array = np.array(img_PIL)</span><br><span class="line"></span><br><span class="line">writer.add_image(<span class="string">&#x27;test&#x27;</span>, img_array, <span class="number">1</span>, dataformats=<span class="string">&#x27;HWC&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># for i in range(100):</span></span><br><span class="line"><span class="comment">#     writer.add_scalar(&quot;y=2x&quot;, 3*i, i)</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<blockquote>
<p>不仅需要进行数据类型的转换，在add_image中还有一些shape的要求：<br>Shape:<br>img_tensor: Default is :math:<code>(3, H, W)</code>. You can use <code>torchvision.utils.make_grid()</code> to<br>convert a batch of tensor into 3xHxW format or call <code>add_images</code> and let us do the job.<br>Tensor with :math:<code>(1, H, W)</code>, :math:<code>(H, W)</code>, :math:<code>(H, W, 3)</code> is also suitable as long as<br>corresponding <code>dataformats</code> argument is passed, e.g. <code>CHW</code>, <code>HWC</code>, <code>HW</code>.</p>
</blockquote>
<p>当前我们数据的格式为(512, 768, 3) :<code>print(img_array.shape)</code>，但是由于不是add_image方法默认的<code>(3, H, W)</code>的形式，因此需要使用dataformats进行定义：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">writer.add_image(&#x27;test&#x27;, img_array, 1, dataformats=&#x27;HWC&#x27;)</span><br></pre></td></tr></table></figure>

<p>然后在进行运行就可正常执行。</p>
<p>Tips：从PIL到numpy，需要在add_image()中指定shape中每一个数字&#x2F;维度表示的含义。</p>
<p>我们再查看一下SummaryWriter类绘制出的图像结果：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418142610602.png" alt="image-20240418142610602"></p>
<p>然后，再读取一张照片，将step参数改为2：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)  <span class="comment"># 将内容存储在logs文件夹下</span></span><br><span class="line">image_path = <span class="string">&quot;../data/train/ants_image/5650366_e22b7e1065.jpg&quot;</span></span><br><span class="line">img_PIL = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">img_array = np.array(img_PIL)</span><br><span class="line">writer.add_image(<span class="string">&#x27;test&#x27;</span>, img_array, <span class="number">2</span>, dataformats=<span class="string">&#x27;HWC&#x27;</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418142925418.png" alt="image-20240418142925418"></p>
<p>此时就可以拖拽切换step查看每次读取的图片。</p>
<h2 id="Transforms的使用"><a href="#Transforms的使用" class="headerlink" title="Transforms的使用"></a>Transforms的使用</h2><p>transforms是 PyTorch 中提供的一个<strong>图像预处理</strong>模块，可以方便地对图像进行各种变换操作。</p>
<h4 id="Transforms的结构与用法"><a href="#Transforms的结构与用法" class="headerlink" title="Transforms的结构与用法"></a>Transforms的结构与用法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># python的用法 -&gt; tensor数据类型</span></span><br><span class="line"><span class="comment"># 通过Transform.ToTensor去解决两个问题</span></span><br><span class="line"><span class="comment"># 1.transforms该如何使用(python)</span></span><br><span class="line"><span class="comment"># 2.为什么需要Tensor数据类型</span></span><br><span class="line"></span><br><span class="line">img_path = <span class="string">&quot;../data/train/ants_image/0013035.jpg&quot;</span></span><br><span class="line">img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs_tf&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.transforms该如何使用(python)</span></span><br><span class="line">tensor_trans = transforms.ToTensor()    <span class="comment"># 该类型返回Tensor类型的图片</span></span><br><span class="line">tensor_img = tensor_trans(img)          <span class="comment"># 将img的图片转换为tensor类型的图片</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.为什么需要Tensor数据类型</span></span><br><span class="line"><span class="comment">#   tensor数据类型包装了一些神经网络所需要的数据基数</span></span><br><span class="line">writer.add_image(<span class="string">&quot;Tensor_img&quot;</span>, tensor_img)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tensor_img)</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418161839081.png" alt="image-20240418161839081"></p>
<h4 id="常见的Transforms"><a href="#常见的Transforms" class="headerlink" title="常见的Transforms"></a>常见的Transforms</h4><p>​	主要就是使用transform类中的各种方法，包括各种输入、输出、作用。</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418162003252.png" alt="image-20240418162003252"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs_trsf&quot;</span>)</span><br><span class="line">img = Image.<span class="built_in">open</span>(<span class="string">&quot;../data/train/ants_image/0013035.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Totensor</span></span><br><span class="line">trans_totensor = transforms.ToTensor()</span><br><span class="line">img_tensor = trans_totensor(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;ToTensor&quot;</span>, img_tensor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Normalize</span></span><br><span class="line"><span class="comment"># output[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br><span class="line"><span class="comment"># 需要输入均值(mean)，标准差(std)</span></span><br><span class="line"><span class="comment"># 将输入的值归一化到(-1， 1)范围之间</span></span><br><span class="line"><span class="built_in">print</span>(img_tensor[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">trans_norm = transforms.Normalize([<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>], [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>])</span><br><span class="line">img_norm = trans_norm(img_tensor)</span><br><span class="line"><span class="built_in">print</span>(img_norm[<span class="number">0</span>][<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">writer.add_image(<span class="string">&quot;Normalize&quot;</span>, img_norm)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>以上代码主要做了什么呢？首先将读入的数据转换为tensor格式，然后将其进行归一化，最后输出归一化结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=768x512 at 0x27AB5995D60&gt;</span><br><span class="line">tensor(0.3137)	# 归一化前原始数据</span><br><span class="line">tensor(-0.3725) # 归一化结果数据</span><br></pre></td></tr></table></figure>

<p>归一化后的图片结果：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418170550169.png" alt="image-20240418170550169"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Resize</span></span><br><span class="line"><span class="comment"># 调整传入的PIIL图像的尺寸</span></span><br><span class="line"><span class="built_in">print</span>(img.size)</span><br><span class="line">trans_resize = transforms.Resize((<span class="number">512</span>, <span class="number">512</span>))</span><br><span class="line"><span class="comment"># img PIL -&gt; resize -&gt; img_resize PIL</span></span><br><span class="line">img_resize = trans_resize(img)</span><br><span class="line"><span class="comment"># img_resize PIL -&gt; totensor -&gt; img_resize tensor</span></span><br><span class="line">img_resize = trans_totensor(img_resize)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>, img_resize, <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(img_resize)</span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\12235\AppData\Roaming\Typora\typora-user-images\image-20240418184956763.png" alt="image-20240418184956763"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compose - resize - 2</span></span><br><span class="line"><span class="comment"># Resize如果只输入一个数的话，会按照比例进行缩放</span></span><br><span class="line">trans_resize_2 = transforms.Resize(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># Compose()中的参数需要一个列表,compose会把前面的输出作为后面的输出，组合到一起</span></span><br><span class="line"><span class="comment"># 因此，需要注意前面的输出的数据类型是否可作为后面的输入类型，否则会报错</span></span><br><span class="line"><span class="comment"># PIL -&gt; PIL -&gt; tensor</span></span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2, trans_totensor])</span><br><span class="line">img_resize_2 = trans_compose(img)</span><br><span class="line">writer.add_image(<span class="string">&quot;Resize&quot;</span>, img_resize_2, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418204455715.png" alt="image-20240418204455715"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RandomCrop</span></span><br><span class="line">trans_random = transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line"><span class="comment"># 此处就是先对图像进行随机裁剪，然后转换为tensor格式</span></span><br><span class="line">trans_compose_2 = transforms.Compose([trans_random, trans_totensor])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>): <span class="comment"># 随机裁剪10次</span></span><br><span class="line">    img_crop = trans_compose_2(img)</span><br><span class="line">    writer.add_image(<span class="string">&quot;RandomCrop&quot;</span>, img_crop, i)</span><br></pre></td></tr></table></figure>

<p>进行了十次随机裁剪：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240418212725362.png" alt="image-20240418212725362"></p>
<p>在类的使用中，一般主要注意以下几点：</p>
<ol>
<li>关注输入输出类型</li>
<li>多看官方文档</li>
<li>关注方法需要什么参数</li>
<li>不知道返回值的时候，使用print()、print（type()）、debug……</li>
</ol>
<h4 id="Torchvision中的数据集使用"><a href="#Torchvision中的数据集使用" class="headerlink" title="Torchvision中的数据集使用"></a>Torchvision中的数据集使用</h4><p>​	在pytorch中可以看到很多已有的可下载的数据集。通过TorchVision可以帮助我们快速的远程下载数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># trochvision中的dataset与transform的联动,在CIFAR10中设置转换方法</span></span><br><span class="line">dataset_transform = torchvision.transforms.Compose([</span><br><span class="line">    torchvision.transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=dataset_transform)</span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=dataset_transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(test_set[0])</span></span><br><span class="line"><span class="comment"># print(test_set.classes)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># img, target = test_set[0]</span></span><br><span class="line"><span class="comment"># print(img)</span></span><br><span class="line"><span class="comment"># print(target)</span></span><br><span class="line"><span class="comment"># print(test_set.classes[target])</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;log_dataset&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    img, target = test_set[i]</span><br><span class="line">    writer.add_image(<span class="string">&quot;test_set&quot;</span>, img, i)</span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501164541811.png" alt="image-20240501164541811"></p>
<h2 id="Dataloader的使用"><a href="#Dataloader的使用" class="headerlink" title="Dataloader的使用"></a>Dataloader的使用</h2><p>​	Dataset是指用于存储和管理数据的类，而Dataloader用于从Dataset中按照指定方式读取数据。<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">Dataloader的官方文档</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备的测试数据集</span></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(dataset=test_data, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>, drop_last=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># batch_size : 每次从数据集中取4个数据进行打包</span></span><br><span class="line"><span class="comment"># drop_last : 如果为True，则会舍弃最后不足一组的数据</span></span><br><span class="line"><span class="comment"># shuffle : 打乱数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试数据集中第一张图片样本</span></span><br><span class="line">img, target = test_data[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(img.shape)</span><br><span class="line"><span class="built_in">print</span>(target)</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;dataloader&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> test_loader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    <span class="comment"># print(imgs.shape)</span></span><br><span class="line">    <span class="comment"># print(targets)</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;test_data&quot;</span>, imgs, step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501185317124.png" alt="image-20240501185317124"></p>
<h2 id="神经网络的搭建"><a href="#神经网络的搭建" class="headerlink" title="神经网络的搭建"></a>神经网络的搭建</h2><p>通过pytorch搭建神经网络主要用到的是torch.nn模块。所有定义的神经网络都应从torch.nn.Module类中继承。</p>
<p>以下是创建了一个最简单的神经网络，输入为一个数字，经过前进函数后，可以将输入加一后输出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = <span class="built_in">input</span> + <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line">x = torch.tensor(<span class="number">1.0</span>)</span><br><span class="line">output = yosheep(x)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h4 id="卷积操作"><a href="#卷积操作" class="headerlink" title="卷积操作"></a>卷积操作</h4><p>例子：</p>
<p>例如有一个5X5的输入图像，其中的每一块都表示这个位置的显色，并且还有一个卷积核。</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501233749834.png" alt="image-20240501233749834"></p>
<p>在进行卷积的过程中，就是将卷积核与输入图的前三行三列进行匹配，然后进行相乘相加，最终就输出一个10：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234037279.png" alt="image-20240501234037279"></p>
<p>当Stride为1时，卷积核在下一次会在图像中移动一步：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234124527.png" alt="image-20240501234124527"></p>
<p>然后到换行时就往下一格，依次进行计算即可，最终计算出结果：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234437099.png" alt="image-20240501234437099"></p>
<p>若Stride&#x3D;2，与等于1不同的是，就是每次会走两步，移动路径如下：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234552051.png" alt="image-20240501234552051"><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234659633.png" alt="image-20240501234659633"><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240501234715674.png" alt="image-20240501234715674"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                      [<span class="number">5</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                      [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line"></span><br><span class="line">kernel = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一个1是输入图片的数量，第二个1是通道数，由于这只是一个二维张量因此通道为1，第一个5是H为高，第二个5是W是宽</span></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">kernel = torch.reshape(kernel, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(kernel.shape)</span><br><span class="line"></span><br><span class="line">output = F.conv2d(<span class="built_in">input</span>, kernel, stride=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 当Stride为1时</span><br><span class="line">torch.Size([1, 1, 5, 5])</span><br><span class="line">torch.Size([1, 1, 3, 3])</span><br><span class="line">tensor([[[[10, 12, 12],</span><br><span class="line">          [18, 16, 16],</span><br><span class="line">          [13,  9,  3]]]])</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 当Stride为2时</span><br><span class="line">torch.Size([1, 1, 5, 5])</span><br><span class="line">torch.Size([1, 1, 3, 3])</span><br><span class="line">tensor([[[[10, 12],</span><br><span class="line">          [13,  3]]]])</span><br></pre></td></tr></table></figure>

<p>填充，会在图像的四周都填充指定数量的列，一般padding的值为0，当padding为1：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502000758746.png" alt="image-20240502000758746"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 当padding=1，Stride=1，此时再进行卷积的结果</span><br><span class="line">tensor([[[[ 1,  3,  4, 10,  8],</span><br><span class="line">          [ 5, 10, 12, 12,  6],</span><br><span class="line">          [ 7, 18, 16, 16,  8],</span><br><span class="line">          [11, 13,  9,  3,  4],</span><br><span class="line">          [14, 13,  9,  7,  4]]]])</span><br></pre></td></tr></table></figure>

<h4 id="卷积层使用"><a href="#卷积层使用" class="headerlink" title="卷积层使用"></a>卷积层使用</h4><p>再pytorch中，卷积操作有一维、二维、三维的操作方法，一般我们对图片使用最多的是二维，也就是其中的conv2d方法。</p>
<p>在conv2d的参数中，outchannel参数的设置，也就是输出通道数，当outchannel为2时，则会有两个卷积核，最终的输出是两个结果的叠加：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502153337184.png" alt="image-20240502153337184"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 搭建一个简单神经网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">6</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 此前进函数输入一个x后，对其进行卷积操作后输出</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;./nn_logs&quot;</span>)</span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    output = yosheep(imgs)</span><br><span class="line">    <span class="comment"># torch.Size([64, 3, 32, 32])</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 此时这个操作，如果是两个channel的图，经过叠加后，形成两个通道，但是若reshape将其变为一个通道，则会使其batch_size变大</span></span><br><span class="line">    <span class="comment"># reshape中变化的参数，若第一个值不知道是多少，则写-1</span></span><br><span class="line">    output = torch.reshape(output, (-<span class="number">1</span>, <span class="number">3</span>, <span class="number">30</span>, <span class="number">30</span>))</span><br><span class="line">    <span class="comment"># torch.Size([64, 6, 30, 30]) -&gt; torch.Size([64, 3, 30, 30])</span></span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step += <span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>卷积后得到的输出：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502161704241.png" alt="image-20240502161704241"></p>
<h4 id="最大池化使用"><a href="#最大池化使用" class="headerlink" title="最大池化使用"></a>最大池化使用</h4><p>最大池化使用的最多的方法还是maxpool2d。池化也是应用池化核，然后通过池化核去输入中进行匹配，不过此时的输出结果是最大的值（池化层默认步长是池化核的大小）：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502162455295.png" alt="image-20240502162455295"></p>
<p>如果匹配到了边缘，则就要看Ceil_module的设置，如果为true，则保留，否则不保留：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502162703002.png" alt="image-20240502162703002"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> MaxPool2d</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># input = torch.tensor([[1, 2, 0, 3, 1],</span></span><br><span class="line"><span class="comment">#                       [0, 1, 2, 3, 1],</span></span><br><span class="line"><span class="comment">#                       [1, 2, 1, 0, 0],</span></span><br><span class="line"><span class="comment">#                       [5, 2, 3, 1, 1],</span></span><br><span class="line"><span class="comment">#                       [2, 1, 0, 1, 1]], dtype=torch.float32)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># input = torch.reshape(input, (-1, 1, 5, 5))</span></span><br><span class="line"><span class="comment"># print(input.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.maxpool1 = MaxPool2d(kernel_size=<span class="number">3</span>, ceil_mode=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = self.maxpool1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"><span class="comment"># output = yosheep(input)</span></span><br><span class="line"><span class="comment"># print(output)</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;nn_maxpool_logs&quot;</span>)</span><br><span class="line">step = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, step)</span><br><span class="line">    output = yosheep(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>最大池化的应用可以想象，将1080p的视频转换为720p，会对画质减小，但是同时视频大小也会大大减小。</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502165016418.png" alt="image-20240502165016418"></p>
<h4 id="非线性激活"><a href="#非线性激活" class="headerlink" title="非线性激活"></a>非线性激活</h4><p><strong>引入非线性关系：</strong> 如果在神经网络中只使用线性操作（如线性加权和），整个网络就会变成一个大的线性函数，多个线性层的组合依然是一个线性变换。非线性激活函数（例如sigmoid、tanh、ReLU等）引入了非线性关系，允许网络学习和表示非线性的模式，这对于解决复杂任务非常关键。</p>
<p>以下使用ReLU演示：</p>
<p>输入经过ReLU处理后，会进行简单的改变，当输入为负数时，则会被变为0：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502174757238.png" alt="image-20240502174757238"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, -<span class="number">0.5</span>],</span><br><span class="line">                      [-<span class="number">1</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">output = torch.reshape(<span class="built_in">input</span>, (-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.relu1 = ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = self.relu1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line">output = yosheep(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 1, 2, 2])</span><br><span class="line">tensor([[1., 0.],</span><br><span class="line">        [0., 3.]])</span><br></pre></td></tr></table></figure>

<p>对图片进行操作，此处使用sigmoid：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.datasets</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU, Sigmoid</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>, -<span class="number">0.5</span>],</span><br><span class="line">                      [-<span class="number">1</span>, <span class="number">3</span>]])</span><br><span class="line"></span><br><span class="line">output = torch.reshape(<span class="built_in">input</span>, (-<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>)</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.relu1 = ReLU()</span><br><span class="line">        self.sigmoid1 = Sigmoid()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = self.sigmoid1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"></span><br><span class="line">step = <span class="number">0</span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;./nn_relu_logs&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    writer.add_images(<span class="string">&quot;input&quot;</span>, imgs, global_step=step)</span><br><span class="line">    output = yosheep(imgs)</span><br><span class="line">    writer.add_images(<span class="string">&quot;output&quot;</span>, output, global_step=step)</span><br><span class="line">    step += <span class="number">1</span></span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502175626811.png" alt="image-20240502175626811"></p>
<h4 id="正则化层"><a href="#正则化层" class="headerlink" title="正则化层"></a>正则化层</h4><p>通过正则化，可以加快神经网络的速度，也可以解决过拟合的问题。（BatchNorm2d）</p>
<h4 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 此处不加drop_last后会报错</span></span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>, drop_last=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># in_features : 196609是拉长后的图片的长度</span></span><br><span class="line">        <span class="comment"># out_features : 输出的特征长度</span></span><br><span class="line">        self.linear1 = Linear(<span class="number">196608</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span><br><span class="line">        output = self.linear1(<span class="built_in">input</span>)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, targets = data</span><br><span class="line">    <span class="built_in">print</span>(imgs.shape)</span><br><span class="line">    <span class="comment"># 要将图片拉长，最后一个参数是宽度，此时拉长后的宽度是未知的，因此要使用-1</span></span><br><span class="line">    <span class="comment"># output = torch.reshape(imgs, (1, 1, 1, -1))</span></span><br><span class="line">    <span class="comment"># 展平数据</span></span><br><span class="line">    output = torch.flatten(imgs)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    output = yosheep(output)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原始图像数据</span></span><br><span class="line">torch.Size([<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>])</span><br><span class="line"><span class="comment"># 展开成一维后的结果</span></span><br><span class="line">torch.Size([<span class="number">196608</span>])</span><br><span class="line"><span class="comment"># Linear后的结果</span></span><br><span class="line">torch.Size([<span class="number">10</span>])</span><br></pre></td></tr></table></figure>



<p>其余在神经网络中还有很多的层，可以在官方文档中查看：<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html">https://pytorch.org/docs/stable/nn.html</a></p>
<h4 id="Sequential的使用与搭建一个小神经网络"><a href="#Sequential的使用与搭建一个小神经网络" class="headerlink" title="Sequential的使用与搭建一个小神经网络"></a>Sequential的使用与搭建一个小神经网络</h4><p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502220559528.png" alt="image-20240502220559528"></p>
<p>根据以上结构，构造对应的神经网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># inchannel是3， outchannel是32， kernelsize为5，padding根据卷积公式计算</span></span><br><span class="line">        self.conv1 = Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 此时maxpool核大小为2</span></span><br><span class="line">        self.maxpool1 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 输入为32，输出为32，padding根据卷积公式计算</span></span><br><span class="line">        self.conv2 = Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 此时maxpool核大小为2</span></span><br><span class="line">        self.maxpool2 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 输入为32，输出为64，padding根据卷积公式计算</span></span><br><span class="line">        self.conv3 = Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 此时maxpool核大小为2</span></span><br><span class="line">        self.maxpool3 = MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        <span class="comment"># 进行展平</span></span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        <span class="comment"># 线性层</span></span><br><span class="line">        self.linear1 = Linear(<span class="number">1024</span>, <span class="number">64</span>)</span><br><span class="line">        self.linear2 = Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.maxpool1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = self.maxpool2(x)</span><br><span class="line">        x = self.conv3(x)</span><br><span class="line">        x = self.maxpool3(x)</span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.linear1(x)</span><br><span class="line">        x = self.linear2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"><span class="built_in">print</span>(yosheep)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 输出结构：</span><br><span class="line">Yosheep(</span><br><span class="line">  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span><br><span class="line">  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  (flatten): Flatten(start_dim=1, end_dim=-1)</span><br><span class="line">  (linear1): Linear(in_features=1024, out_features=64, bias=True)</span><br><span class="line">  (linear2): Linear(in_features=64, out_features=10, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>此时用一个全1的数据对建立好的模型进行一个测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建一个全是1的数据</span></span><br><span class="line"><span class="comment"># batchsize为64，3通道，32*32</span></span><br><span class="line"><span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))</span><br><span class="line">output = yosheep(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 输出</span><br><span class="line">torch.Size([64, 10])</span><br></pre></td></tr></table></figure>

<p>此时对于以上的神经网络init函数中的内容，也可以使用Sequential方法来对其简化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">	 	<span class="built_in">super</span>().__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"><span class="built_in">print</span>(yosheep)</span><br></pre></td></tr></table></figure>

<p>也可以通过SummaryWriter来直接通过模型显示模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">writer = SummaryWriter(<span class="string">&quot;logs_nn_sequential&quot;</span>)</span><br><span class="line">writer.add_graph(yosheep, <span class="built_in">input</span>)</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502231119409.png" alt="image-20240502231119409"></p>
<p>通过双击即可详细查看内部的操作：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240502231212830.png" alt="image-20240502231212830"></p>
<h4 id="损失函数与反向传播"><a href="#损失函数与反向传播" class="headerlink" title="损失函数与反向传播"></a>损失函数与反向传播</h4><p>损失函数的计算方法，可以看出loss对于模型来说是越小越好的：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240503135959750.png" alt="image-20240503135959750"></p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240503140751617.png" alt="image-20240503140751617"></p>
<p><strong>loss的作用：</strong></p>
<ol>
<li>计算实际输出和目标之间的差距</li>
<li>为我们更新输出提供一定的依据（反向传播）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss</span><br><span class="line"></span><br><span class="line">inputs = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=torch.float32)</span><br><span class="line">targets = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">5</span>], dtype=torch.float32)</span><br><span class="line"></span><br><span class="line">inputs = torch.reshape(inputs, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line">targets = torch.reshape(targets, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">loss = L1Loss()</span><br><span class="line">result = loss(inputs, targets)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(0.6667)</span><br></pre></td></tr></table></figure>

<p><strong>平方差MSELoss</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss_mse = nn.MSELoss()</span><br><span class="line">result_mse = loss_mse(inputs, targets)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(1.3333)</span><br></pre></td></tr></table></figure>

<p><strong>交叉熵</strong></p>
<p>比如此时有一个三分类问题。此时有一个图片，一个神经网络，以及获取的一些数据：</p>
<p><img src="https://sunnydog-1314279731.cos.ap-shanghai.myqcloud.com/image-20240503142944521.png" alt="image-20240503142944521"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = torch.tensor([<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.3</span>])</span><br><span class="line">y = torch.tensor([<span class="number">1</span>])</span><br><span class="line">x = torch.reshape(x, (<span class="number">1</span>, <span class="number">3</span>)) <span class="comment"># batch_size = 1, 数据大小为3</span></span><br><span class="line">loss_cross = nn.CrossEntropyLoss() <span class="comment"># 计算交叉熵</span></span><br><span class="line">result_cross = loss_cross(x, y)</span><br><span class="line"><span class="built_in">print</span>(result_cross)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(1.1019)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss, Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">    imgs, target = data</span><br><span class="line">    outputs = yosheep(imgs)</span><br><span class="line">    result_loss = loss(outputs, target)</span><br><span class="line">    result_loss.backward()</span><br></pre></td></tr></table></figure>

<p>以上就可以求出每个数据的loss值，并且可以得到损失函数的一个梯度，进而可以通过这个方向进行梯度下降。</p>
<h4 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h4><p>通过反向传播，可以计算出需要调节的参数和其对应的梯度，进而可以用优化器根据梯度来进行调整。</p>
<p>优化器：optim，可以使用其中的算法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss, Conv2d, MaxPool2d, Flatten, Linear, Sequential</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;./dataset&quot;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,</span><br><span class="line">                                       transform=torchvision.transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Yosheep</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.model1 = Sequential(</span><br><span class="line">            Conv2d(<span class="number">3</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, padding=<span class="number">2</span>),</span><br><span class="line">            MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Flatten(),</span><br><span class="line">            Linear(<span class="number">1024</span>, <span class="number">64</span>),</span><br><span class="line">            Linear(<span class="number">64</span>, <span class="number">10</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.model1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">yosheep = Yosheep()</span><br><span class="line"><span class="comment"># 定义优化器，使用其中的SGD算法</span></span><br><span class="line">optim = torch.optim.SGD(yosheep.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 多次执行，看每轮的loss</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> dataloader:</span><br><span class="line">        imgs, target = data</span><br><span class="line">        outputs = yosheep(imgs)</span><br><span class="line">        result_loss = loss(outputs, target)</span><br><span class="line">        <span class="comment"># 把每个可调节参数的梯度调为0</span></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        <span class="comment"># 反向传播，获取每个可调节参数的梯度</span></span><br><span class="line">        result_loss.backward()</span><br><span class="line">        optim.step() <span class="comment"># 进行调优</span></span><br><span class="line">        running_loss = running_loss + result_loss</span><br><span class="line">    <span class="built_in">print</span>(running_loss)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># loss下降的过程</span><br><span class="line">tensor(18641.3711, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(16151.2676, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(15427.0596, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://yosheep.github.io">YoSheep</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://yosheep.github.io/posts/44904.html">https://yosheep.github.io/posts/44904.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://yosheep.github.io" target="_blank">YoSheep's 学习笔记</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/AI/">AI</a></div><div class="post_share"><div class="social-share" data-image="/img/yeah_circle.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/posts/17013.html" title="PHP反序列化"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">PHP反序列化</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/6245f930.html" title="大模型提示词---Prompt Engineering（提示工程）"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-12-18</div><div class="title">大模型提示词---Prompt Engineering（提示工程）</div></div></a></div><div><a href="/posts/7547cd0e.html" title="让AI也懵圈：一次CTF中的对抗样本生成与应用"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-10</div><div class="title">让AI也懵圈：一次CTF中的对抗样本生成与应用</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/yeah_circle.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">YoSheep</div><div class="author-info__description">欢迎各位师傅交流学习</br>vx: sunny下划线yosheep</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">23</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">20</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/YoSheep"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/yosheep" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:sunny_cxw@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">佬说：“搞安全的，技术不重要，重要的是要会想。”</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Pytorch%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">1.</span> <span class="toc-text">Pytorch加载数据</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Dataset"><span class="toc-number">1.0.1.</span> <span class="toc-text">Dataset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dataloader"><span class="toc-number">1.0.2.</span> <span class="toc-text">Dataloader</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TensorBoard%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">2.</span> <span class="toc-text">TensorBoard的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">示例</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Transforms%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">4.</span> <span class="toc-text">Transforms的使用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Transforms%E7%9A%84%E7%BB%93%E6%9E%84%E4%B8%8E%E7%94%A8%E6%B3%95"><span class="toc-number">4.0.1.</span> <span class="toc-text">Transforms的结构与用法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E7%9A%84Transforms"><span class="toc-number">4.0.2.</span> <span class="toc-text">常见的Transforms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Torchvision%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BD%BF%E7%94%A8"><span class="toc-number">4.0.3.</span> <span class="toc-text">Torchvision中的数据集使用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Dataloader%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">5.</span> <span class="toc-text">Dataloader的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%90%AD%E5%BB%BA"><span class="toc-number">6.</span> <span class="toc-text">神经网络的搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C"><span class="toc-number">6.0.1.</span> <span class="toc-text">卷积操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%B7%E7%A7%AF%E5%B1%82%E4%BD%BF%E7%94%A8"><span class="toc-number">6.0.2.</span> <span class="toc-text">卷积层使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E4%BD%BF%E7%94%A8"><span class="toc-number">6.0.3.</span> <span class="toc-text">最大池化使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%BF%80%E6%B4%BB"><span class="toc-number">6.0.4.</span> <span class="toc-text">非线性激活</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E5%B1%82"><span class="toc-number">6.0.5.</span> <span class="toc-text">正则化层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%B1%82"><span class="toc-number">6.0.6.</span> <span class="toc-text">线性层</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Sequential%E7%9A%84%E4%BD%BF%E7%94%A8%E4%B8%8E%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%B0%8F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">6.0.7.</span> <span class="toc-text">Sequential的使用与搭建一个小神经网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">6.0.8.</span> <span class="toc-text">损失函数与反向传播</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E5%8C%96%E5%99%A8"><span class="toc-number">6.0.9.</span> <span class="toc-text">优化器</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/6d596838.html" title="NexusCTF Write-Up By YoSheep">NexusCTF Write-Up By YoSheep</a><time datetime="2025-10-09T13:52:25.000Z" title="发表于 2025-10-10 00:52:25">2025-10-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/4da32f64.html" title="Gap Year Review --- 在路上的一年">Gap Year Review --- 在路上的一年</a><time datetime="2025-09-21T14:18:05.000Z" title="发表于 2025-09-22 00:18:05">2025-09-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/b97f01f6.html" title="Java安全篇(3)-CC链">Java安全篇(3)-CC链</a><time datetime="2025-08-25T06:26:28.000Z" title="发表于 2025-08-25 16:26:28">2025-08-25</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/105b1196.html" title="XML 外部实体注入（XXE）漏洞基本原理">XML 外部实体注入（XXE）漏洞基本原理</a><time datetime="2025-08-24T11:40:38.000Z" title="发表于 2025-08-24 21:40:38">2025-08-24</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/b1433c19.html" title="Java安全篇(2)-ysoserial使用">Java安全篇(2)-ysoserial使用</a><time datetime="2025-08-23T13:56:54.000Z" title="发表于 2025-08-23 23:56:54">2025-08-23</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 - 2025 By YoSheep</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'iSjR5V9ZIytpvfNU137OlQGH-gzGzoHsz',
      appKey: '9jj4DuX9kTm6wiDHKR1Llu7T',
      avatar: 'monsterid',
      serverURLs: 'https://isjr5v9z.lc-cn-n1-shared.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.jsdelivr.net/npm/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div></body></html>